{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameFormatFn(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        record = element\n",
    "        name = record.get('Candidate')\n",
    "        name = name.upper()\n",
    "        name = name.replace(\"\\\"\",\"\")\n",
    "        name = name.replace(\"\\\\\",\"\")\n",
    "        name = name.replace(', JR.', '')\n",
    "        name = name.replace(', SR.', '')\n",
    "        name = name.replace(', II', '')\n",
    "        name = name.replace(', III', '')\n",
    "        name = name.replace(', JR', '')\n",
    "        name = name.replace(', SR', '')\n",
    "        name = name.replace(' JR', '')\n",
    "        name = name.replace(' SR', '')\n",
    "        name = name.replace(' II', '')\n",
    "        name = name.replace(' III', '')\n",
    "        name = name.replace('.','')\n",
    "        \n",
    "        if \",\" in name:\n",
    "            name = name.split()\n",
    "            record['Candidate'] = name[0] + \" \" + name[1]\n",
    "        else:\n",
    "            name = name.split()\n",
    "            if len(name) == 1:\n",
    "                record['Candidate'] = name[0]\n",
    "            else:\n",
    "                record['Candidate'] = name[-1] + ', ' + name[0]\n",
    "                \n",
    "        return [record]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RunsNamePreGroupFn(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        record = element\n",
    "        name = record.pop('Candidate')\n",
    "        \n",
    "        return [(name, record)]\n",
    "    \n",
    "class CandNamePreGroupFn(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        record = element\n",
    "        name = record.pop('Name')\n",
    "        \n",
    "        return[(name, record)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveEmptyRunsFn(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        name, record = element\n",
    "        \n",
    "        if len(record['Runs']) == 0 or len(record['Cand']) == 0:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            return [element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreatePreFinalRecordsFn(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        name, record_dict = element\n",
    "        record_lst = []\n",
    "        runsKey_lst = []\n",
    "        \n",
    "        for x in record_dict['Runs']:\n",
    "            for y in record_dict['Cand']:\n",
    "                cand_dict = {'Election_ID':x['Election_ID'],'Candidate_Votes':x['Candidate_Votes']}\n",
    "                cand_dict['Candidate_Label'] = cand_dict['Election_ID'][:4] + y['ID']\n",
    "                runsKey = cand_dict['Candidate_Label'] + cand_dict['Election_ID'][4:]\n",
    "                cand_dict['Runs_ID'] = runsKey\n",
    "                \n",
    "                if runsKey not in runsKey_lst:\n",
    "                    runsKey_lst.append(runsKey)\n",
    "                    record_lst.append(cand_dict)\n",
    "            \n",
    "        return record_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'sound-cider-252823'\n",
    "BUCKET = 'gs://gerryandhao'\n",
    "DIR_PATH = BUCKET + '/output/' + datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S') + '/'\n",
    "\n",
    "options = {\n",
    "    'runner': 'DataflowRunner',\n",
    "    'job_name': 'transform-runs',\n",
    "    'project': PROJECT_ID,\n",
    "    'temp_location': BUCKET + '/temp',\n",
    "    'staging_location': BUCKET + '/staging',\n",
    "    'machine_type': 'n1-standard-4', # machine types listed here: https://cloud.google.com/compute/docs/machine-types\n",
    "    'num_workers': 4\n",
    "}\n",
    "opts = beam.pipeline.PipelineOptions(flags=[], **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline('DataflowRunner', options = opts) as p:\n",
    "    query_results = p | 'Read from BigQuery for txt' >> beam.io.Read(beam.io.BigQuerySource(query = 'SELECT * FROM MIT_modeled.Runs'))\n",
    "    cand_query_results = p | 'Read Candidates_Beam_DF_Jupyter from BigQuery' >> beam.io.Read(beam.io.BigQuerySource(query = 'SELECT Name, ID from fec_modeled.Candidates_Beam_DF_Jupyter'))\n",
    "\n",
    "    #perform name standardization by calling the NameFormat ParDo\n",
    "    new_pcoll = query_results | 'Perform name standardization' >> beam.ParDo(NameFormatFn())\n",
    "    \n",
    "    #pregrouping for runs\n",
    "    runs_name_pcoll = new_pcoll | 'Runs pregroup processing' >> beam.ParDo(RunsNamePreGroupFn())\n",
    "    \n",
    "    \n",
    "    #pregrouping for candidates table\n",
    "    cand_name_pcoll = cand_query_results | 'Cand pregroup processing' >> beam.ParDo(CandNamePreGroupFn())\n",
    "    \n",
    "    #perform cogroupbykey\n",
    "    group_pcoll = {'Runs':runs_name_pcoll,'Cand':cand_name_pcoll} | 'Grouping' >> beam.CoGroupByKey()\n",
    "    \n",
    "    #removing empties\n",
    "    cleaned_group_pcoll = group_pcoll | \"Remove empty runs record\" >> beam.ParDo(RemoveEmptyRunsFn())\n",
    "    \n",
    "    #create near final records\n",
    "    pre_final_pcoll = cleaned_group_pcoll | \"Create near final records\" >> beam.ParDo(CreatePreFinalRecordsFn())\n",
    "    \n",
    "       \n",
    "    dataset_id = 'MIT_modeled'\n",
    "    table_id ='Runs_Beam_DF_Jupyter'\n",
    "    schema_id = 'Runs_ID:STRING, Candidate_Label:STRING, Candidate_Votes:INTEGER, Election_ID:STRING'\n",
    "    \n",
    "    # write the output results as a table in BigQuery\n",
    "    pre_final_pcoll | 'Write to BigQuery' >> beam.io.WriteToBigQuery(dataset=dataset_id, \n",
    "                                                    table=table_id, \n",
    "                                                    schema=schema_id,\n",
    "                                                    project=PROJECT_ID,\n",
    "                                                    create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "                                                    write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE,\n",
    "                                                    batch_size=int(100))\n",
    "    \n",
    "    result = p.run()\n",
    "    result.wait_until_finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (beam_venv)",
   "language": "python",
   "name": "beam_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
