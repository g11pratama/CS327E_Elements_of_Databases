{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\\\\Hello\".replace(\"\\\\\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameFormatFn(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        record = element\n",
    "        name = record.get('Candidate')\n",
    "        name = name.upper()\n",
    "        name = name.replace(\"\\\"\",\"\")\n",
    "        name = name.replace(\"\\\\\",\"\")\n",
    "        name = name.replace(', JR.', '')\n",
    "        name = name.replace(', SR.', '')\n",
    "        name = name.replace(', II', '')\n",
    "        name = name.replace(', III', '')\n",
    "        name = name.replace(', JR', '')\n",
    "        name = name.replace(', SR', '')\n",
    "        name = name.replace(' JR', '')\n",
    "        name = name.replace(' SR', '')\n",
    "        name = name.replace(' II', '')\n",
    "        name = name.replace(' III', '')\n",
    "        name = name.replace('.','')\n",
    "        \n",
    "        if \",\" in name:\n",
    "            name = name.split()\n",
    "            record['Candidate'] = name[0] + \" \" + name[1]\n",
    "        else:\n",
    "            name = name.split()\n",
    "            if len(name) == 1:\n",
    "                record['Candidate'] = name[0]\n",
    "            else:\n",
    "                record['Candidate'] = name[-1] + ', ' + name[0]\n",
    "                \n",
    "        return [record]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunsNamePreGroupFn(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        record = element\n",
    "        name = record.pop('Candidate')\n",
    "        \n",
    "        return [(name, record)]\n",
    "    \n",
    "class CandNamePreGroupFn(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        record = element\n",
    "        name = record.pop('Name')\n",
    "        \n",
    "        return[(name, record)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveEmptyRunsFn(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        name, record = element\n",
    "        \n",
    "        if len(record['Runs']) == 0 or len(record['Cand']) == 0:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            return [element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreatePreFinalRecordsFn(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        name, record_dict = element\n",
    "        record_lst = []\n",
    "        runsKey_lst = []\n",
    "        \n",
    "        for x in record_dict['Runs']:\n",
    "            for y in record_dict['Cand']:\n",
    "                cand_dict = {'Election_ID':x['Election_ID'],'Candidate_Votes':x['Candidate_Votes']}\n",
    "                cand_dict['Candidate_Label'] = cand_dict['Election_ID'][:4] + y['ID']\n",
    "                runsKey = cand_dict['Candidate_Label'] + cand_dict['Election_ID'][4:]\n",
    "                cand_dict['Runs_ID'] = cand_dict['Candidate_Label'] + cand_dict['Election_ID'][4:]\n",
    "                \n",
    "                if runsKey not in runsKey_lst:\n",
    "                    cand_dict['Candidate_Label'] + cand_dict['Election_ID'][4:]\n",
    "                    record_lst.append(cand_dict)\n",
    "            \n",
    "        return record_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'sound-cider-252823'\n",
    "\n",
    "# Project ID is needed for BigQuery data source, even for local execution.\n",
    "options = {\n",
    "    'project': PROJECT_ID\n",
    "}\n",
    "opts = beam.pipeline.PipelineOptions(flags=[], **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Dataset sound-cider-252823:temp_dataset_9f9b7dd89fb745c3a7346d872308f2ca does not exist so we will create it as temporary with location=None\n",
      "WARNING:root:Dataset sound-cider-252823:temp_dataset_503d48c579cd4985a831bb5ee52cb0d1 does not exist so we will create it as temporary with location=None\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline('DirectRunner', options = opts) as p:\n",
    "    \n",
    "    #Because of the time limits, we only extract the first 100 rows of data.\n",
    "    query_results = p | 'Read from BigQuery for txt' >> beam.io.Read(beam.io.BigQuerySource(query = 'SELECT * FROM MIT_modeled.Runs'))\n",
    "    cand_query_results = p | 'Read Candidates_Beam_DF_Jupyter from BigQuery' >> beam.io.Read(beam.io.BigQuerySource(query = 'SELECT Name, ID from fec_modeled.Candidates_Beam_DF_Jupyter'))\n",
    "\n",
    "    #write PCollection to log file\n",
    "    #query_results | 'Write to input.txt' >> WriteToText('input.txt')\n",
    "                                                                                             \n",
    "    #cand_query_results | 'Write cand input to txt' >> WriteToText('cand_input.txt')\n",
    "    \n",
    "    #perform name standardization by calling the NameFormat ParDo\n",
    "    new_pcoll = query_results | 'Perform name standardization' >> beam.ParDo(NameFormatFn())\n",
    "    \n",
    "    #pregrouping for runs\n",
    "    runs_name_pcoll = new_pcoll | 'Runs pregroup processing' >> beam.ParDo(RunsNamePreGroupFn())\n",
    "    \n",
    "    #runs_name_pcoll | 'Write runs pregroup process results to txt' >> WriteToText('runs_name_pregroup_results.txt')\n",
    "    \n",
    "    #pregrouping for candidates table\n",
    "    cand_name_pcoll = cand_query_results | 'Cand pregroup processing' >> beam.ParDo(CandNamePreGroupFn())\n",
    "    \n",
    "    #cand_name_pcoll | 'Write cand pregroup process results to txt' >> WriteToText('cand_name_pregroup_results.txt')\n",
    "    \n",
    "    group_pcoll = {'Runs':runs_name_pcoll,'Cand':cand_name_pcoll} | 'Grouping' >> beam.CoGroupByKey()\n",
    "    \n",
    "    group_pcoll | \"Write grouped results to txt\" >> WriteToText('grouped_results.txt')\n",
    "    \n",
    "    cleaned_group_pcoll = group_pcoll | \"Remove empty runs record\" >> beam.ParDo(RemoveEmptyRunsFn())\n",
    "    \n",
    "    cleaned_group_pcoll | \"Write cleaned group to txt\" >> WriteToText('cleaned_grouped_results.txt')\n",
    "    \n",
    "    pre_final_pcoll = cleaned_group_pcoll | \"Create near final records\" >> beam.ParDo(CreatePreFinalRecordsFn())\n",
    "    \n",
    "    pre_final_pcoll | \"Write pre final records to txt\" >> WriteToText('pre_final_results.txt')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#     qualified_table_name = PROJECT_ID + ':MIT_modeled.Runs_Beam_Jupyter'\n",
    "#     #Transaction_Type:STRING, Date:DATE, Amount:INTEGER, Payee_ID:STRING, Contribution_ID:STRING, Year:INTEGER, Committee_Label:STRING, Candidate_Label:STRING\n",
    "#     # change the column \"Date\" in to type date\n",
    "#     table_schema = 'Candidate:STRING, Candidate_Votes:INTEGER, Election_ID:STRING'\n",
    "    \n",
    "#     # write the output results as a table in BigQuery\n",
    "#     new_pcoll | 'Write to BigQuery' >> beam.io.Write(beam.io.BigQuerySink(qualified_table_name,\n",
    "#                                                     schema=table_schema,  \n",
    "#                                                     create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "#                                                     write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (beam_venv)",
   "language": "python",
   "name": "beam_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
